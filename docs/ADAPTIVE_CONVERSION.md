# ğŸ“š Sistema Adaptativo de ConversiÃ³n PDFâ†’Markdown

**VersiÃ³n:** 2.0 (Noviembre 2025)  
**Basado en:** guia-instalacion.md + receta-pdf-markdown.md  
**Hardware:** macOS M4 (MPS), Ubuntu RTX 3070 (CUDA), Windows (CPU/CUDA)

---

## ğŸ¯ FilosofÃ­a: "No Reinventar la Rueda"

Este sistema implementa una estrategia **adaptativa e inteligente** para conversiÃ³n PDFâ†’Markdown, seleccionando automÃ¡ticamente las mejores herramientas segÃºn el tipo de PDF.

### Problema que Resuelve

**No todos los PDFs son iguales:**

1. **PDF Nativo** (texto seleccionable): Aplicar OCR completo serÃ­a desperdiciar 5-7 minutos de GPU cuando pdfplumber lo hace en 5 segundos.

2. **PDF Escaneado** (imagen pura): Intentar extraer texto con pdfplumber darÃ­a basura; se necesita OCR con GPU.

3. **PDF Mixto** (texto + imÃ¡genes no copiables): Requiere detecciÃ³n inteligente para aplicar OCR solo donde es necesario.

### SoluciÃ³n: DetecciÃ³n AutomÃ¡tica + Estrategia Adaptativa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF.pdf   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDFTypeDetector     â”‚ â† Analiza primeras 3-10 pÃ¡ginas (< 1s)
â”‚  (pdfplumber ligero) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
   Â¿QuÃ© tipo?
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚       â”‚         â”‚         â”‚
NATIVE  SCANNED   MIXED    UNKNOWN
   â”‚       â”‚         â”‚         â”‚
   â–¼       â–¼         â–¼         â–¼
pdfplumber marker-pdf docling  fallback
(5-10s)   (5-7min)  (30-60s)  (manual)
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core Dependencies (Versiones Testeadas)

| Herramienta | VersiÃ³n | PropÃ³sito | Performance |
|------------|---------|-----------|------------|
| **pdfplumber** | 0.11.4 | PDFs nativos | ~5-10s/50pÃ¡g |
| **marker-pdf** | â‰¥1.0.0 | PDFs escaneados | ~5-7min GPU |
| **docling** | â‰¥2.18.0 | PDFs mixtos | **(Pendiente)** ~30-60s |
| **EasyOCR** | 1.7.1 | OCR backend | Con marker |
| **PyTorch** | 2.5.1 | GPU (CUDA/MPS) | CrÃ­tico |

### Hardware Soportado

**macOS M4 (MPS):**
```bash
pip install torch==2.5.1 torchvision==0.20.1
```
- RAM: 16GB | Performance: ~6-7 min/50pÃ¡g | Workers: 2

**Ubuntu RTX 3070 (CUDA 12.1):**
```bash
pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121
```
- VRAM: 8GB | Performance: ~4-5 min/50pÃ¡g | Workers: 4

**Windows CPU/CUDA:**
```bash
# CPU
pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cpu
# CUDA (si tienes GPU)
pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121
```

---

## ğŸ“Š DetecciÃ³n de Tipo de PDF

### PDFTypeDetector

Clasifica PDFs analizando densidad de texto extraÃ­ble.

**Uso:**
```python
from pdf_type_detector import PDFTypeDetector

detector = PDFTypeDetector()
pdf_type, stats = detector.detect("paper.pdf", quick=True)

print(f"Tipo: {pdf_type.value}")
print(f"Estrategia: {stats['recommended_strategy']}")
```

**CLI:**
```bash
python scripts/conversion/pdf_type_detector.py paper.pdf
```

**Output:**
```
ğŸ“Š ANÃLISIS DE TIPO DE PDF
============================================================
Archivo: paper.pdf
Tipo: NATIVE
PÃ¡ginas totales: 58
PÃ¡ginas analizadas: 10
PÃ¡ginas con texto: 10
PÃ¡ginas vacÃ­as: 0
Ratio texto: 100.0%
Estrategia: pdfplumber (rÃ¡pido, alta fidelidad)
============================================================
```

---

## ğŸ”„ ConversiÃ³n Adaptativa

### AdaptivePDFConverter

**Uso BÃ¡sico:**
```python
from adaptive_converter import AdaptivePDFConverter

converter = AdaptivePDFConverter(sources_dir="sources")
result = converter.convert_single("paper.pdf")

if result["success"]:
    print(f"âœ… Markdown: {result['markdown_path']}")
```

**CLI:**
```bash
# ConversiÃ³n automÃ¡tica
python scripts/conversion/adaptive_converter.py paper.pdf

# Con validaciÃ³n Ollama
python scripts/conversion/adaptive_converter.py paper.pdf --ollama

# Forzar estrategia
python scripts/conversion/adaptive_converter.py paper.pdf --strategy scanned
```

---

## ğŸ“‹ Estrategias de ConversiÃ³n

### 1. NATIVE: PDFs con Texto Seleccionable

**Herramienta:** pdfplumber  
**Performance:** 5-10 segundos para 50 pÃ¡ginas  
**Uso:**
```python
# AutomÃ¡tico si PDFTypeDetector detecta NATIVE
markdown, metadata = converter._convert_native(pdf_path, conversion_id)
```

**CaracterÃ­sticas:**
- ExtracciÃ³n directa de texto embebido
- Tablas automÃ¡ticas con pdfplumber
- Sin OCR (rÃ¡pido y preciso)

### 2. SCANNED: PDFs Escaneados (Imagen)

**Herramienta:** marker-pdf + EasyOCR + GPU  
**Performance:** 5-7 minutos con GPU para 50 pÃ¡ginas  
**Uso:**
```python
# AutomÃ¡tico si PDFTypeDetector detecta SCANNED
markdown, metadata = converter._convert_scanned(pdf_path, conversion_id)
```

**CaracterÃ­sticas:**
- OCR con modelos Surya (marker-pdf)
- EasyOCR como backend
- Requiere GPU para performance aceptable
- Cleanup automÃ¡tico con gemma3:12b (opcional)

### 3. MIXED: PDFs HÃ­bridos (Pendiente)

**Herramienta:** `docling` (con fallback a `pdfplumber`)  
**Performance:** 30-60 segundos para 50 pÃ¡ginas (estimado)  
**Uso:**
```python
# AutomÃ¡tico si PDFTypeDetector detecta MIXED
# Actualmente usa el fallback a _convert_native
markdown, metadata = converter._convert_mixed(pdf_path, conversion_id)
```

**CaracterÃ­sticas:**
- DetecciÃ³n inteligente de regiones
- OCR solo donde es necesario
- **Actualmente, esta estrategia no estÃ¡ implementada y el sistema utiliza `_convert_native` como fallback.**

---

## ğŸ’¾ Sistema de Tracking

### ConversionTracker (SQLite)

Tracking automÃ¡tico con detecciÃ³n de duplicados por SHA-256.

**Uso:**
```python
from conversion_db import ConversionTracker

with ConversionTracker() as tracker:
    # Verificar duplicado
    is_dup, existing_id = tracker.is_duplicate(pdf_path)
    
    # Registrar conversiÃ³n
    conv_id = tracker.add_conversion(pdf_path, status="processing")
    
    # Actualizar estado
    tracker.update_conversion(conv_id, status="success", pages=58)
    
    # EstadÃ­sticas
    stats = tracker.get_statistics()
    print(f"Total conversiones: {stats['total_conversions']}")
```

**Base de datos:** `sources_local/metadata/conversion_tracker.db`

**Tablas:**
- `conversions`: Registro de cada PDF procesado
- `validation_reports`: Reportes de validaciÃ³n con gemma3
- `conversion_errors`: Errores encontrados

---

## ğŸ¤– ValidaciÃ³n con Ollama (Opcional)

### gemma3:12b Local

**InstalaciÃ³n:**
```bash
# Instalar Ollama desde https://ollama.ai
ollama pull gemma3:12b
```

**Uso:**
```bash
# Activar validaciÃ³n
python scripts/conversion/adaptive_converter.py paper.pdf --ollama
```

**QuÃ© hace gemma3:12b:**
1. Valida estructura Markdown (tÃ­tulos, listas, tablas)
2. Detecta errores OCR (lâ†’1, Oâ†’0, rnâ†’m)
3. Calcula confidence score (0-100)
4. Limpia errores si confidence < 60

**Ejemplo de validaciÃ³n:**
```json
{
  "structure_ok": true,
  "ocr_quality": 95,
  "tables_ok": true,
  "confidence": 92,
  "notes": "Excellent conversion, minor spacing in one table"
}
```

---

## ğŸ“ Estructura de Directorios

```
vermi-academic-rag/
â”œâ”€â”€ sources_local/                    # Local only (ignorado por Git)
â”‚   â”œâ”€â”€ originals/             # PDFs originales
â”‚   â”œâ”€â”€ converted/             # Markdowns generados
â”‚   â”œâ”€â”€ metadata/              # conversion_tracker.db
â”‚   â””â”€â”€ reports/               # Reportes JSON (si usa --ollama)
â”œâ”€â”€ data/                       # Datos procesados
â”‚   â”œâ”€â”€ raw/                   # PDFs backup
â”‚   â”œâ”€â”€ processed/             # Chunks procesados
â”‚   â”œâ”€â”€ embeddings/            # Cache de embeddings
â”‚   â”œâ”€â”€ metadata/              # Perfiles de conversiÃ³n
â”‚   â””â”€â”€ validation/            # Reportes de validaciÃ³n
â”œâ”€â”€ config/
â”‚   â””â”€â”€ profiles/              # Perfiles de conversiÃ³n personalizados
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ conversion/
â”‚       â”œâ”€â”€ adaptive_converter.py      # Conversor principal
â”‚       â”œâ”€â”€ pdf_type_detector.py       # Detector de tipo
â”‚       â”œâ”€â”€ conversion_db.py           # Sistema de tracking
â”‚       â”œâ”€â”€ conversion_profiles.py     # Sistema de perfiles
â”‚       â””â”€â”€ requirements.txt           # Dependencias
â””â”€â”€ docs/
    â””â”€â”€ ADAPTIVE_CONVERSION.md         # Esta guÃ­a
```

**âš ï¸ Importante:** Todo `sources_local/` estÃ¡ en `.gitignore` (BYOS policy).

---

## ğŸš€ Quickstart

### 1. InstalaciÃ³n AutomÃ¡tica

```bash
# Clonar repositorio
git clone https://github.com/lizkarol/vermi-academic-rag.git
cd vermi-academic-rag

# Setup automÃ¡tico (detecta plataforma)
./setup.sh
```

### 2. ConversiÃ³n BÃ¡sica

```bash
# Activar entorno
source .venv/bin/activate

# Detectar tipo de PDF
python scripts/conversion/pdf_type_detector.py paper.pdf

# Convertir automÃ¡ticamente
python scripts/conversion/adaptive_converter.py paper.pdf
```

### 3. Verificar Output

```bash
# Ver Markdown generado
cat sources_local/converted/paper.md

# Ver estadÃ­sticas
python -c "
from scripts.conversion.conversion_db import ConversionTracker
with ConversionTracker() as t:
    stats = t.get_statistics()
    print(f'Total: {stats[\"total_conversions\"]}')
    print(f'Confidence promedio: {stats[\"average_confidence\"]}')
"
```

---

## ğŸ“Š Benchmarks

### Resultados Reales (ont66t-Valdivia-Ayaca-Cuela-Rojas.pdf)

**Hardware:** Mac M4 (MPS)  
**PDF:** 58 pÃ¡ginas, NATIVE (100% texto)  
**Resultado:**
- DetecciÃ³n: < 1 segundo
- ConversiÃ³n: 1.6 segundos
- PÃ¡ginas procesadas: 58
- Tablas extraÃ­das: 8
- Estrategia: pdfplumber

**Performance vs. Sistema Anterior:**
- Sistema viejo (marker-pdf para todo): ~5-7 minutos
- Sistema adaptativo (pdfplumber): 1.6 segundos
- **Ganancia: 200x mÃ¡s rÃ¡pido** ğŸš€

---

## ğŸ”§ Opciones Avanzadas

### CLI Completo

```bash
python scripts/conversion/adaptive_converter.py <pdf> [opciones]

Opciones:
  --force              Forzar reconversiÃ³n (ignorar duplicados)
  --ollama             Activar validaciÃ³n con gemma3:12b
  --strategy TIPO      Forzar estrategia (native/scanned/mixed)
  --sources-dir DIR    Directorio sources custom
  --profile NOMBRE     Usar perfil de conversiÃ³n personalizado
  --help               Mostrar ayuda completa
```

### Python API

```python
from adaptive_converter import AdaptivePDFConverter

# ConfiguraciÃ³n avanzada
converter = AdaptivePDFConverter(
    sources_dir="sources",
    use_ollama=True,
    ollama_url="http://localhost:11434",
    ollama_model="gemma3:12b",
    force_strategy="native"  # Forzar estrategia
)

# ConversiÃ³n con opciones
result = converter.convert_single(
    pdf_path="paper.pdf",
    force=True,         # Ignorar duplicados
    quick_detect=True   # Solo analizar 3 pÃ¡ginas
)

# Resultado
print(f"Success: {result['success']}")
print(f"Tipo: {result['pdf_type']}")
print(f"Estrategia: {result['strategy']}")
print(f"Markdown: {result['markdown_path']}")
print(f"Tiempo: {result['elapsed_time']:.1f}s")
```

---

## ğŸ› Troubleshooting

### Error: marker-pdf no encontrado

```bash
pip install marker-pdf>=1.0.0
```

### Error: Ollama connection refused

```bash
# Verificar Ollama estÃ¡ corriendo
ollama list

# Si no, iniciar:
ollama serve

# En otra terminal:
ollama pull gemma3:12b
```

### ConversiÃ³n muy lenta

1. Verificar tipo de PDF (puede estar usando marker-pdf innecesariamente)
2. Deshabilitar Ollama: `--no-ollama` (ahorra 10-30s)
3. Usar `--strategy native` si sabes que tiene texto

### PDF detectado incorrectamente

```bash
# Forzar estrategia manualmente
python scripts/conversion/adaptive_converter.py paper.pdf --strategy native
```

---

## ğŸ“– DocumentaciÃ³n Adicional

- **GuÃ­a de instalaciÃ³n completa:** `docs/guide/guia-instalacion.md`
- **Receta funcional PDFâ†’MD:** `docs/guide/receta-pdf-markdown.md`
- **README principal:** `README.md`
- **Esquema de datos RAG:** `docs/DATA_SCHEMA.md`

---

## ğŸ“ PrÃ³ximos Pasos

1. **Convertir tu primer PDF:**
   ```bash
   python scripts/conversion/adaptive_converter.py tu_paper.pdf
   ```

2. **Generar chunks parafraseados** (Fase 1):
   - Usar Markdown + `scripts/chunking/generate_cards_local.md`
   - LLM manual (Gemini, GPT-4, Claude)

3. **Validar chunks:**
   ```bash
   python scripts/chunking/validate_chunks.py --file chunks.jsonl --mode schema
   ```

4. **Contribuir al dataset:**
   ```bash
   cp chunks.jsonl dataset/chunks_enriched/
   git add dataset/chunks_enriched/chunks.jsonl
   git commit -m "feat: Add chunks from [paper name]"
   ```

---

**Sistema adaptativo operacional. Listo para conversiÃ³n a escala. BYOS compliant. ğŸš€**
